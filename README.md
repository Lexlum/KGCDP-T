KGCDP-T: Interpreting Knowledge Graph into Text by Content Ordering and Dynamic Planning with Three-Level Reconstruction

In this paper, we focus on interpreting the given knowledge graph (KG) into a piece of semantically coherent and logically reasonable text (i.e., KG-to-text, a more specific task belonging to graph-to-text), which connects knowledge graphs and texts to significantly improve the applicability of knowledge graph in more realistic Natural Language Generation (NLG) scenarios. In order to overcome the challenge of semantic gap between the structural knowledge graph and unstructured text, a novel pipeline-based knowledge graph-interpretation model KGCDP-T consisting of Content Ordering and Dynamic Planning has been proposed. Specifically, the first “pipe” Content Ordering converts the entire knowledge graph into several triple-groups, then into an ordered triple-sequence, so as to plan the ordering by which the “content” in the given knowledge graph should be interpreted. Next, an entity-sequence will be derived from the above ordered triple-sequence, where the second “pipe” Dynamic Planning captures the context shifting entailed in the entity-sequence via Memory Network. In this way, the entity-sequence-level and memory-level contexts will be learned and fused to guarantee that the generated interpreting-text could adopt more context-adaptive tokens catering to the derived entity-sequence. Moreover, the Three-Level Reconstruction mechanism has also been injected across the entire pipeline of the proposed KGCDP-T model, to further capture the critical features transferred among the triple-groups, the ordered triple-sequence, the generated text-sequence and the given knowledge graph. According to the experimental results, compared with the state-of-art KG-to-text models, our proposed KGCDP-T can achieve the overall best knowledge graph-interpretation performance on content integrity, sentence fluency, and logic coherency.
